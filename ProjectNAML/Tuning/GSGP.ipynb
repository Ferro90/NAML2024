{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gp_module\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna \n",
    "from ydata_profiling import ProfileReport\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error , mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import warnings\n",
    "from xgboost import XGBRegressor\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from typing import List, Callable\n",
    "import json \n",
    "from catboost import CatBoostRegressor\n",
    "#from lightgbm import LGBMRegressor\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "import gp_module\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from typing import List, Callable\n",
    "X_train = pd.read_csv('../Data/dataset/X_train.csv')\n",
    "features_number = X_train.shape[1]\n",
    "X_train = pd.read_csv('../Data/dataset/X_train.csv').values\n",
    "y_train = pd.read_csv('../Data/dataset/Y_train.csv').values.ravel()\n",
    "X_val = pd.read_csv('../Data/dataset/X_val.csv').values\n",
    "y_val = pd.read_csv('../Data/dataset/Y_val.csv').values.ravel()\n",
    "X_test = pd.read_csv('../Data/dataset/X_test.csv').values\n",
    "y_test = pd.read_csv('../Data/dataset/Y_test.csv').values.ravel()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbol:\n",
    "    def __init__(self, is_function: bool, arity: int, name: str, value: float = 0.0):\n",
    "        self.is_function = is_function\n",
    "        self.arity = arity\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, root: Symbol, children: List['Node'] = None):\n",
    "        self.root = root\n",
    "        self.children = children or []\n",
    "\n",
    "class Individual:\n",
    "    def __init__(self, root: Node):\n",
    "        self.root = root\n",
    "        self.fitness = float('inf')\n",
    "\n",
    "class SymbolicRegressor:\n",
    "    def __init__(self, params: dict):\n",
    "        self.params = params\n",
    "        self.symbols = self.create_symbols()\n",
    "        self.population = []\n",
    "        self.best_individual = None\n",
    "\n",
    "    def create_symbols(self):\n",
    "        symbols = [\n",
    "            Symbol(True, 2, \"+\"),\n",
    "            Symbol(True, 2, \"-\"),\n",
    "            Symbol(True, 2, \"*\"),\n",
    "            Symbol(True, 2, \"/\")\n",
    "        ]\n",
    "        symbols.extend([Symbol(False, 0, f\"x{i}\") for i in range(self.params['num_variables'])])\n",
    "        symbols.extend([Symbol(False, 0, str(random.uniform(self.params['min_constant'], self.params['max_constant']))) \n",
    "                        for _ in range(self.params['num_constants'])])\n",
    "        return symbols\n",
    "\n",
    "    def create_tree(self, depth: int, max_depth: int) -> Node:\n",
    "        if depth == max_depth or (depth > 0 and random.random() < 0.5):\n",
    "            return Node(random.choice([s for s in self.symbols if not s.is_function]))\n",
    "        \n",
    "        root = random.choice([s for s in self.symbols if s.is_function])\n",
    "        children = [self.create_tree(depth + 1, max_depth) for _ in range(root.arity)]\n",
    "        return Node(root, children)\n",
    "\n",
    "    def create_population(self):\n",
    "        self.population = [Individual(self.create_tree(0, self.params['max_depth'])) \n",
    "                           for _ in range(self.params['population_size'])]\n",
    "\n",
    "    def evaluate(self, individual: Individual, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        predictions = np.array([self.eval_tree(individual.root, x) for x in X])\n",
    "        return np.sqrt(np.mean((predictions - y) ** 2))\n",
    "\n",
    "    def eval_tree(self, node: Node, x: np.ndarray) -> float:\n",
    "        if not node.root.is_function:\n",
    "            return float(node.root.name) if node.root.name[0] != 'x' else x[int(node.root.name[1:])]\n",
    "        \n",
    "        if len(node.children) == 0:\n",
    "            return 0  # Return a default value if there are no children\n",
    "        \n",
    "        if len(node.children) == 1:\n",
    "            return self.eval_tree(node.children[0], x)  # Return the value of the single child\n",
    "        \n",
    "        left = self.eval_tree(node.children[0], x)\n",
    "        right = self.eval_tree(node.children[1], x) if len(node.children) > 1 else 0\n",
    "\n",
    "        if node.root.name == '+': return left + right\n",
    "        if node.root.name == '-': return left - right\n",
    "        if node.root.name == '*': return left * right\n",
    "        if node.root.name == '/': return left / right if right != 0 else 1\n",
    "\n",
    "    def tournament_selection(self) -> Individual:\n",
    "        tournament = random.sample(self.population, self.params['tournament_size'])\n",
    "        return min(tournament, key=lambda ind: ind.fitness)\n",
    "\n",
    "    def crossover(self, parent1: Individual, parent2: Individual) -> Individual:\n",
    "        def swap_subtree(node1: Node, node2: Node) -> Node:\n",
    "            if random.random() < 0.5:\n",
    "                return Node(node2.root, node2.children)\n",
    "            if not node1.root.is_function:\n",
    "                return Node(node1.root)\n",
    "            new_children = [swap_subtree(c1, c2) for c1, c2 in zip(node1.children, node2.children)]\n",
    "            return Node(node1.root, new_children)\n",
    "        \n",
    "        new_root = swap_subtree(parent1.root, parent2.root)\n",
    "        return Individual(new_root)\n",
    "\n",
    "    def mutation(self, individual: Individual) -> Individual:\n",
    "        def mutate_node(node: Node) -> Node:\n",
    "            if random.random() < self.params['mutation_rate']:\n",
    "                return self.create_tree(0, self.params['max_depth'])\n",
    "            if not node.root.is_function:\n",
    "                return Node(node.root)\n",
    "            new_children = [mutate_node(child) for child in node.children]\n",
    "            return Node(node.root, new_children)\n",
    "        \n",
    "        new_root = mutate_node(individual.root)\n",
    "        return Individual(new_root)\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.create_population()\n",
    "        for generation in range(self.params['num_generations']):\n",
    "            for ind in self.population:\n",
    "                ind.fitness = self.evaluate(ind, X, y)\n",
    "            \n",
    "            self.best_individual = min(self.population, key=lambda ind: ind.fitness)\n",
    "            new_population = [self.best_individual]  # Elitism\n",
    "\n",
    "            while len(new_population) < self.params['population_size']:\n",
    "                if random.random() < self.params['crossover_rate']:\n",
    "                    parent1, parent2 = self.tournament_selection(), self.tournament_selection()\n",
    "                    offspring = self.crossover(parent1, parent2)\n",
    "                else:\n",
    "                    offspring = self.mutation(self.tournament_selection())\n",
    "                new_population.append(offspring)\n",
    "\n",
    "            self.population = new_population\n",
    "\n",
    "            if generation % 10 == 0:  # Print progress every 10 generations\n",
    "                print(f\"Generation {generation}: Best Fitness = {self.best_individual.fitness}\")\n",
    "\n",
    "        return self.best_individual.fitness\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.array([self.eval_tree(self.best_individual.root, x) for x in X])\n",
    "\n",
    "# Example usage\n",
    "\n",
    "    \n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'population_size': trial.suggest_int('population_size', 50, 300),\n",
    "        'num_generations': trial.suggest_int('num_generations', 50, 200),\n",
    "        'tournament_size': trial.suggest_int('tournament_size', 2, 20),\n",
    "        'crossover_rate': trial.suggest_float('crossover_rate', 0.1, 1.0),\n",
    "        'mutation_rate': trial.suggest_float('mutation_rate', 0.01, 0.5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_variables': features_number,  \n",
    "        'num_constants': trial.suggest_int('num_constants', 5, 30),\n",
    "        'min_constant': trial.suggest_float('min_constant', -10, -1),\n",
    "        'max_constant': trial.suggest_float('max_constant', 1, 10)\n",
    "    }\n",
    "    print(f\"Trying parameters: {params}\")\n",
    "\n",
    "    regressor = SymbolicRegressor(params)\n",
    "\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_val = regressor.predict(X_val)\n",
    "\n",
    "    mse_val = np.mean((y_val - y_pred_val) ** 2)\n",
    "\n",
    "    return mse_val  \n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)  #\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_regressor = SymbolicRegressor(best_params)\n",
    "best_regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_test = best_regressor.predict(X_test)\n",
    "test_mse = np.mean((y_test - y_pred_test) ** 2)\n",
    "print(f\"Test MSE: {test_mse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
